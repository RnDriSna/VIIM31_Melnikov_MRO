import numpy as np

def ho_kashyap(X, y, alpha=0.1, max_iter=1000):
  """
  Реализация алгоритма Хо-Кашьяпа для обучения линейного классификатора.

  Args:
    X: Матрица признаков обучающей выборки, формы (n_samples, n_features).
    y: Вектор меток классов обучающей выборки, формы (n_samples,).
    alpha: Коэффициент обучения.
    max_iter: Максимальное число итераций.

  Returns:
    w: Вектор весов обученного классификатора.
    b: Пороговое значение обученного классификатора.
  """

  # Инициализация весов и порогового значения.
  w = np.zeros(X.shape[1])
  b = 1

  # Цикл обучения.
  for i in range(max_iter):
    # Вычисление ошибок классификации.
    e = X.dot(w) - b
    # Обновление весов и порогового значения.
    w = (X.T.dot(X)).I.dot(X.T.dot(b + alpha * e))
    b = b + alpha * (e + np.abs(e))

  # Возврат обученных параметров.
  return w, b

# Пример использования алгоритма.
X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])
y = np.array([1, 1, -1, -1])

# Обучение классификатора.
w, b = ho_kashyap(X, y)

# Классификация новых данных.
new_data = np.array([[9, 10]])
new_data_class = np.sign(new_data.dot(w) - b)

# Вывод результата.
print("Класс новых данных:", new_data_class)